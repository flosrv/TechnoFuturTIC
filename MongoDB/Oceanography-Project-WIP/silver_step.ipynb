{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_postgresql_creds = r\"C:\\Users\\f.gionnane\\Documents\\Data Engineering\\Credentials\\postgresql_creds.json\"\n",
    "\n",
    "with open(path_postgresql_creds, 'r') as file:\n",
    "    content = json.load(file)\n",
    "    user = content[\"user\"]\n",
    "    password = content[\"password\"]\n",
    "    host = content[\"host\"]\n",
    "    port = content[\"port\"]\n",
    "\n",
    "db = \"Oceanography_ML_Project\"\n",
    "schema_bronze = \"Bronze\"\n",
    "schema_silver = \"Silver\"\n",
    "\n",
    "# Créer l'engine PostgreSQL\n",
    "engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{db}\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les Données des Tables de la couche de Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Chargement des métadonnées du schéma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Métadonnées chargées avec succès.\n",
      "\n",
      "🔢 Nombre total de tables dans le schéma : 79\n",
      "\n",
      "🌊 Tables marines trouvées : 39\n",
      "🌧️ Tables météo trouvées : 39\n",
      "🐋 Tables de bouées trouvées : 1\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données de la table 'buoys_datas'...\n",
      "📦 Données récupérées pour 'buoys_datas'.\n",
      "✅ Table 'buoys_datas' chargée avec succès! Nombre de bouées (lignes) : 39\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données pour la table Marine : station_42058_marine_central caribbean...\n",
      "📦 Données récupérées pour la station 42058 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42058! Nombre de lignes collectées : 6942\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_POTA2_marine_potato point, ak...\n",
      "📦 Données récupérées pour la station POTA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station POTA2! Nombre de lignes collectées : 2334\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_LONF1_marine_long key, fl...\n",
      "📦 Données récupérées pour la station LONF1 (Marine).\n",
      "🌊 Données Marine chargées pour la station LONF1! Nombre de lignes collectées : 6862\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_MDRM1_marine_mt_ desert rock, me...\n",
      "📦 Données récupérées pour la station MDRM1 (Marine).\n",
      "🌊 Données Marine chargées pour la station MDRM1! Nombre de lignes collectées : 1168\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51001_marine_northwestern hawaii one...\n",
      "📦 Données récupérées pour la station 51001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51001! Nombre de lignes collectées : 6938\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_MRKA2_marine_middle rock light, ak...\n",
      "📦 Données récupérées pour la station MRKA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station MRKA2! Nombre de lignes collectées : 2334\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_SBIO1_marine_south bass island, oh...\n",
      "📦 Données récupérées pour la station SBIO1 (Marine).\n",
      "🌊 Données Marine chargées pour la station SBIO1! Nombre de lignes collectées : 1167\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46053_marine_east santa barbara...\n",
      "📦 Données récupérées pour la station 46053 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46053! Nombre de lignes collectées : 6985\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_41044_marine_ne st martin...\n",
      "📦 Données récupérées pour la station 41044 (Marine).\n",
      "🌊 Données Marine chargées pour la station 41044! Nombre de lignes collectées : 6939\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44027_marine_jonesport, me...\n",
      "📦 Données récupérées pour la station 44027 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44027! Nombre de lignes collectées : 6941\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46087_marine_neah bay...\n",
      "📦 Données récupérées pour la station 46087 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46087! Nombre de lignes collectées : 6993\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46029_marine_columbia river bar...\n",
      "📦 Données récupérées pour la station 46029 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46029! Nombre de lignes collectées : 6986\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46027_marine_st georges...\n",
      "📦 Données récupérées pour la station 46027 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46027! Nombre de lignes collectées : 6989\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44025_marine_long island...\n",
      "📦 Données récupérées pour la station 44025 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44025! Nombre de lignes collectées : 6961\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42036_marine_west tampa...\n",
      "📦 Données récupérées pour la station 42036 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42036! Nombre de lignes collectées : 6914\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46014_marine_pt arena...\n",
      "📦 Données récupérées pour la station 46014 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46014! Nombre de lignes collectées : 6990\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46022_marine_eel river...\n",
      "📦 Données récupérées pour la station 46022 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46022! Nombre de lignes collectées : 7003\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46088_marine_new dungeness...\n",
      "📦 Données récupérées pour la station 46088 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46088! Nombre de lignes collectées : 6986\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46084_marine_cape edgecumbe...\n",
      "📦 Données récupérées pour la station 46084 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46084! Nombre de lignes collectées : 6944\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_BURL1_marine_southwest pass, la...\n",
      "📦 Données récupérées pour la station BURL1 (Marine).\n",
      "🌊 Données Marine chargées pour la station BURL1! Nombre de lignes collectées : 1166\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46025_marine_santa monica basin...\n",
      "📦 Données récupérées pour la station 46025 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46025! Nombre de lignes collectées : 6982\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42002_marine_west gulf...\n",
      "📦 Données récupérées pour la station 42002 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42002! Nombre de lignes collectées : 1947\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42056_marine_yucatan basin...\n",
      "📦 Données récupérées pour la station 42056 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42056! Nombre de lignes collectées : 6943\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51002_marine_southwest hawaii...\n",
      "📦 Données récupérées pour la station 51002 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51002! Nombre de lignes collectées : 6935\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46006_marine_southeast papa...\n",
      "📦 Données récupérées pour la station 46006 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46006! Nombre de lignes collectées : 6945\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_FFIA2_marine_five fingers, ak...\n",
      "📦 Données récupérées pour la station FFIA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station FFIA2! Nombre de lignes collectées : 1169\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_SANF1_marine_sand key, fl...\n",
      "📦 Données récupérées pour la station SANF1 (Marine).\n",
      "🌊 Données Marine chargées pour la station SANF1! Nombre de lignes collectées : 6902\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46071_marine_western aleutians...\n",
      "📦 Données récupérées pour la station 46071 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46071! Nombre de lignes collectées : 6942\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42012_marine_orange beach...\n",
      "📦 Données récupérées pour la station 42012 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42012! Nombre de lignes collectées : 6928\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44020_marine_nantucket sound...\n",
      "📦 Données récupérées pour la station 44020 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44020! Nombre de lignes collectées : 6947\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46086_marine_san clemente basin...\n",
      "📦 Données récupérées pour la station 46086 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46086! Nombre de lignes collectées : 6986\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46072_marine_central aleutians 230 nm sw dutch harbor...\n",
      "📦 Données récupérées pour la station 46072 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46072! Nombre de lignes collectées : 6945\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_41008_marine_grays reef...\n",
      "📦 Données récupérées pour la station 41008 (Marine).\n",
      "🌊 Données Marine chargées pour la station 41008! Nombre de lignes collectées : 6973\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42001_marine_mid gulf...\n",
      "📦 Données récupérées pour la station 42001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42001! Nombre de lignes collectées : 1794\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51000_marine_northern hawaii one...\n",
      "📦 Données récupérées pour la station 51000 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51000! Nombre de lignes collectées : 6945\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44065_marine_new york harbor entrance...\n",
      "📦 Données récupérées pour la station 44065 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44065! Nombre de lignes collectées : 6931\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46078_marine_albatross bank...\n",
      "📦 Données récupérées pour la station 46078 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46078! Nombre de lignes collectées : 6938\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46001_marine_western gulf of alaska...\n",
      "📦 Données récupérées pour la station 46001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46001! Nombre de lignes collectées : 6937\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46069_marine_south santa rosa...\n",
      "📦 Données récupérées pour la station 46069 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46069! Nombre de lignes collectées : 6961\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données pour la table Meteo : station_LONF1_meteo_long key, fl...\n",
      "📦 Données récupérées pour la station LONF1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station LONF1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_POTA2_meteo_potato point, ak...\n",
      "📦 Données récupérées pour la station POTA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station POTA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46071_meteo_western aleutians...\n",
      "📦 Données récupérées pour la station 46071 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46071! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_BURL1_meteo_southwest pass, la...\n",
      "📦 Données récupérées pour la station BURL1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station BURL1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46053_meteo_east santa barbara...\n",
      "📦 Données récupérées pour la station 46053 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46053! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44065_meteo_new york harbor entrance...\n",
      "📦 Données récupérées pour la station 44065 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44065! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46084_meteo_cape edgecumbe...\n",
      "📦 Données récupérées pour la station 46084 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46084! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46006_meteo_southeast papa...\n",
      "📦 Données récupérées pour la station 46006 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46006! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46027_meteo_st georges...\n",
      "📦 Données récupérées pour la station 46027 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46027! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44020_meteo_nantucket sound...\n",
      "📦 Données récupérées pour la station 44020 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44020! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46022_meteo_eel river...\n",
      "📦 Données récupérées pour la station 46022 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46022! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46072_meteo_central aleutians 230 nm sw dutch harbor...\n",
      "📦 Données récupérées pour la station 46072 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46072! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_MRKA2_meteo_middle rock light, ak...\n",
      "📦 Données récupérées pour la station MRKA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station MRKA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46025_meteo_santa monica basin...\n",
      "📦 Données récupérées pour la station 46025 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46025! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46014_meteo_pt arena...\n",
      "📦 Données récupérées pour la station 46014 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46014! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46086_meteo_san clemente basin...\n",
      "📦 Données récupérées pour la station 46086 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46086! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_SBIO1_meteo_south bass island, oh...\n",
      "📦 Données récupérées pour la station SBIO1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station SBIO1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46088_meteo_new dungeness...\n",
      "📦 Données récupérées pour la station 46088 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46088! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42058_meteo_central caribbean...\n",
      "📦 Données récupérées pour la station 42058 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42058! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46078_meteo_albatross bank...\n",
      "📦 Données récupérées pour la station 46078 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46078! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42056_meteo_yucatan basin...\n",
      "📦 Données récupérées pour la station 42056 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42056! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42012_meteo_orange beach...\n",
      "📦 Données récupérées pour la station 42012 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42012! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51001_meteo_northwestern hawaii one...\n",
      "📦 Données récupérées pour la station 51001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46069_meteo_south santa rosa...\n",
      "📦 Données récupérées pour la station 46069 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46069! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51002_meteo_southwest hawaii...\n",
      "📦 Données récupérées pour la station 51002 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51002! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_41044_meteo_ne st martin...\n",
      "📦 Données récupérées pour la station 41044 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 41044! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42002_meteo_west gulf...\n",
      "📦 Données récupérées pour la station 42002 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42002! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44027_meteo_jonesport, me...\n",
      "📦 Données récupérées pour la station 44027 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44027! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46029_meteo_columbia river bar...\n",
      "📦 Données récupérées pour la station 46029 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46029! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51000_meteo_northern hawaii one...\n",
      "📦 Données récupérées pour la station 51000 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51000! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42036_meteo_west tampa...\n",
      "📦 Données récupérées pour la station 42036 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42036! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_41008_meteo_grays reef...\n",
      "📦 Données récupérées pour la station 41008 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 41008! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_SANF1_meteo_sand key, fl...\n",
      "📦 Données récupérées pour la station SANF1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station SANF1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_FFIA2_meteo_five fingers, ak...\n",
      "📦 Données récupérées pour la station FFIA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station FFIA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46001_meteo_western gulf of alaska...\n",
      "📦 Données récupérées pour la station 46001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42001_meteo_mid gulf...\n",
      "📦 Données récupérées pour la station 42001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_MDRM1_meteo_mt_ desert rock, me...\n",
      "📦 Données récupérées pour la station MDRM1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station MDRM1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46087_meteo_neah bay...\n",
      "📦 Données récupérées pour la station 46087 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46087! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44025_meteo_long island...\n",
      "📦 Données récupérées pour la station 44025 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44025! Nombre de lignes collectées : 2448\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🏆 Chargement des données terminé avec succès !\n",
      "🐋 Total des données bouées chargées : 1 - Nombre de bouées (lignes) : 39\n",
      "🌊 Total des données marines chargées : 39 - Nombre total de lignes : 228592\n",
      "🌧️ Total des données météorologiques chargées : 39 - Nombre total de lignes : 95472\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n"
     ]
    }
   ],
   "source": [
    "# Charger les métadonnées du schéma existant\n",
    "metadata = MetaData(schema=schema_bronze)\n",
    "\n",
    "print(\"\\n🔍 Chargement des métadonnées du schéma...\")\n",
    "metadata.reflect(bind=conn)\n",
    "print(\"✅ Métadonnées chargées avec succès.\\n\")\n",
    "\n",
    "# Récupérer les noms des tables\n",
    "table_names = [t.name for t in metadata.sorted_tables]\n",
    "print(f\"🔢 Nombre total de tables dans le schéma : {len(table_names)}\\n\")\n",
    "\n",
    "# Filtrer les tables en fonction du contenu de leur nom\n",
    "marine_tables = {t for t in table_names if \"marine\" in t.lower()}\n",
    "meteo_tables = {t for t in table_names if \"meteo\" in t.lower()}\n",
    "buoys_data_table = {t for t in table_names if \"buoy\" in t.lower()}\n",
    "\n",
    "print(f\"🌊 Tables marines trouvées : {len(marine_tables)}\")\n",
    "print(f\"🌧️ Tables météo trouvées : {len(meteo_tables)}\")\n",
    "print(f\"🐋 Tables de bouées trouvées : {len(buoys_data_table)}\\n\")\n",
    "\n",
    "# Initialiser le dictionnaire des résultats\n",
    "buoys_datas = {}\n",
    "\n",
    "# Compteurs pour suivre le nombre de tables chargées avec succès\n",
    "marine_data_count = 0\n",
    "meteo_data_count = 0\n",
    "buoys_data_count = 0\n",
    "\n",
    "# Compteur pour le nombre total de lignes\n",
    "total_marine_rows = 0\n",
    "total_meteo_rows = 0\n",
    "total_buoys_rows = 0  # Changer ici pour compter le nombre de lignes (bouées)\n",
    "\n",
    "# Vérifier et récupérer les données de la table \"buoys_datas\"\n",
    "if buoys_data_table:\n",
    "    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "    print(\"🔄 Chargement des données de la table 'buoys_datas'...\")\n",
    "\n",
    "    try:\n",
    "        buoys_datas_raw = fetch_table_data(schema=schema_bronze, conn=conn, table_name=next(iter(buoys_data_table)), as_df=True)\n",
    "\n",
    "        if buoys_datas_raw is not None:\n",
    "            print(\"📦 Données récupérées pour 'buoys_datas'.\")\n",
    "\n",
    "            # Conversion JSON → dict si nécessaire\n",
    "            if isinstance(buoys_datas_raw, str):\n",
    "                buoys_datas_raw = json.loads(buoys_datas_raw)\n",
    "\n",
    "            elif isinstance(buoys_datas_raw, pd.DataFrame) and \"Station ID\" in buoys_datas_raw.columns:\n",
    "                # Convertir en dictionnaire avec \"Station ID\" comme clé\n",
    "                buoys_datas_raw = buoys_datas_raw.set_index(\"Station ID\").to_dict(orient=\"index\")\n",
    "\n",
    "            # Ajouter au dictionnaire principal directement avec les Station ID comme clés\n",
    "            buoys_datas.update(buoys_datas_raw)\n",
    "            buoys_data_count += 1\n",
    "            total_buoys_rows += len(buoys_datas_raw)  # Compter le nombre de bouées\n",
    "            print(f\"✅ Table 'buoys_datas' chargée avec succès! Nombre de bouées (lignes) : {total_buoys_rows}\\n\")\n",
    "        else:\n",
    "            print(\"⚠️ Aucun résultat trouvé dans 'buoys_datas'.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement de 'buoys_datas': {e}\\n\")\n",
    "\n",
    "# Associer les tables marine et meteo en fonction du station_id et récupérer leurs données\n",
    "for table_set, label, icon, counter, total_rows in [\n",
    "    (marine_tables, \"Marine\", \"🌊\", marine_data_count, total_marine_rows),\n",
    "    (meteo_tables, \"Meteo\", \"🌧️\", meteo_data_count, total_meteo_rows)\n",
    "]:\n",
    "    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "    for table_name in table_set:\n",
    "        print(f\"🔄 Chargement des données pour la table {label} : {table_name}...\")\n",
    "\n",
    "        try:\n",
    "            station_id = table_name.split(\"_\")[1]\n",
    "\n",
    "            # Vérifier si la station existe déjà dans buoys_datas, sinon initialiser un dictionnaire\n",
    "            if station_id not in buoys_datas:\n",
    "                buoys_datas[station_id] = {}\n",
    "\n",
    "            # Récupérer les données\n",
    "            data = fetch_table_data(schema=schema_bronze, conn=conn, table_name=table_name, as_df=True)\n",
    "\n",
    "            if data is not None:\n",
    "                print(f\"📦 Données récupérées pour la station {station_id} ({label}).\")\n",
    "\n",
    "                if isinstance(data, str):\n",
    "                    data = pd.DataFrame(json.loads(data))\n",
    "                elif isinstance(data, dict):\n",
    "                    data = pd.DataFrame(data)\n",
    "\n",
    "                # Ajouter les données au dictionnaire de bouées sous la station_id\n",
    "                buoys_datas[station_id][f\"{label} DataFrame\"] = data\n",
    "                counter += 1\n",
    "                total_rows += len(data)  # Ajouter le nombre de lignes collectées\n",
    "                print(f\"{icon} Données {label} chargées pour la station {station_id}! Nombre de lignes collectées : {len(data)}\\n\")\n",
    "            else:\n",
    "                print(f\"⚠️ Aucun résultat trouvé pour la station {station_id} ({label}).\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors du chargement des données {label} pour {table_name} : {e}\\n\")\n",
    "\n",
    "    # Mise à jour des compteurs après le chargement des données pour chaque catégorie\n",
    "    if label == \"Marine\":\n",
    "        marine_data_count = counter\n",
    "        total_marine_rows = total_rows\n",
    "    elif label == \"Meteo\":\n",
    "        meteo_data_count = counter\n",
    "        total_meteo_rows = total_rows\n",
    "\n",
    "# Finalement, afficher un récapitulatif global\n",
    "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "print(f\"🏆 Chargement des données terminé avec succès !\")\n",
    "print(f\"🐋 Total des données bouées chargées : {buoys_data_count} - Nombre de bouées (lignes) : {total_buoys_rows}\")\n",
    "print(f\"🌊 Total des données marines chargées : {marine_data_count} - Nombre total de lignes : {total_marine_rows}\")\n",
    "print(f\"🌧️ Total des données météorologiques chargées : {meteo_data_count} - Nombre total de lignes : {total_meteo_rows}\")\n",
    "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_silver_merged_df = []  \n",
    "list_failed_dfs = []        \n",
    "\n",
    "number_marine_data = 0\n",
    "number_meteo_data = 0\n",
    "number_merged_data = 0\n",
    "\n",
    "marine_data_conversion = 0\n",
    "meteo_data_conversion = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HANDLING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling Null Values in Marine data for Buoy 41008\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 41008\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 41044\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 41044\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 42001\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 42001\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 42002\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 42002\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 42012\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 42012\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 42036\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 42036\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 42056\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 42056\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 42058\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 42058\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 44020\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 44020\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 44025\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 44025\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 44027\n",
      "Dropped columns (100% missing): air_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, water_temperature, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 44027\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 44065\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 44065\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46001\n",
      "Dropped columns (100% missing): air_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, water_temperature, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46001\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46006\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46006\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46014\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46014\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46022\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46022\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46025\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46025\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46027\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46027\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46029\n",
      "Dropped columns (100% missing): air_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, water_temperature, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46029\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46053\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46053\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46069\n",
      "Dropped columns (100% missing): air_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, water_temperature, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46069\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46071\n",
      "Dropped columns (100% missing): air_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, water_temperature, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46071\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46072\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46072\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46078\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46078\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46084\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46084\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46086\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46086\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46087\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46087\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 46088\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 46088\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 51000\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 51000\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 51001\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 51001\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy 51002\n",
      "Dropped columns (100% missing): visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, pressure, air_temperature, water_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy 51002\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy BURL1\n",
      "Dropped columns (100% missing): wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, water_temperature, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_gust, pressure, air_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy BURL1\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy FFIA2\n",
      "Dropped columns (100% missing): wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, water_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy FFIA2\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy LONF1\n",
      "Dropped columns (100% missing): wind_gust, wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, water_temperature, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, pressure, air_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy LONF1\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy MDRM1\n",
      "Dropped columns (100% missing): wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, water_temperature, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy MDRM1\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy MRKA2\n",
      "Dropped columns (100% missing): wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, water_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_gust, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy MRKA2\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy POTA2\n",
      "Dropped columns (100% missing): wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, water_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy POTA2\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy SANF1\n",
      "Dropped columns (100% missing): wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, water_temperature, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, wind_speed, wind_gust, pressure, air_temperature, dewpoint, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy SANF1\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n",
      "Handling Null Values in Marine data for Buoy SBIO1\n",
      "Dropped columns (100% missing): wave_height, dominant_wave_period, average_wave_period, dominant_wave_direction, water_temperature, dewpoint, visibility, water_level_above_mean\n",
      "Imputed columns (<50% missing, median): wind_direction, air_temperature, 3hr_pressure_tendency\n",
      "Handling Null Values in Weather data for Buoy SBIO1\n",
      "Skipped non-numeric columns: temperature_2m, relative_humidity_2m, dew_point_2m, precipitation, rain, showers, pressure_msl, surface_pressure, cloud_cover, cloud_cover_low, cloud_cover_mid, cloud_cover_high, visibility, wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm\n"
     ]
    }
   ],
   "source": [
    "# Traitement des valeurs nulles\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"Handling Null Values in Marine data for Buoy {station_id}\")\n",
    "        tables[\"Marine DataFrame\"] = handle_null_values(tables[\"Marine DataFrame\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error handling Marine Null Values: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"Handling Null Values in Weather data for Buoy {station_id}\")\n",
    "        tables[\"Meteo DataFrame\"] = handle_null_values(tables[\"Meteo DataFrame\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error handling Meteo Null Values: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOUR RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Processing and resampling marine data for station 41008...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 41008...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 41044...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 41044...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 42001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 42001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 42002...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 42002...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 42012...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 42012...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 42036...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 42036...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 42056...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 42056...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 42058...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 42058...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 44020...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 44020...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 44025...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 44025...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 44027...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 44027...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 44065...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 44065...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46006...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46006...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46014...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46014...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46022...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46022...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46025...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46025...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46027...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46027...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46029...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46029...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46053...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46053...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46069...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46069...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46071...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46071...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46072...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46072...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46078...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46078...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46084...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46084...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46086...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46086...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46087...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46087...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 46088...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 46088...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 51000...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 51000...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 51001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 51001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station 51002...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station 51002...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station BURL1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station BURL1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station FFIA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station FFIA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station LONF1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station LONF1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station MDRM1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station MDRM1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station MRKA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station MRKA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station POTA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station POTA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station SANF1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station SANF1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "🔁 Processing and resampling marine data for station SBIO1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "🔁 Processing and resampling weather data for station SBIO1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n"
     ]
    }
   ],
   "source": [
    "# Resampling des données et stockage dans un nouveau compartiment du dictionnaire\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"🔁 Processing and resampling marine data for station {station_id}...\")\n",
    "        tables[\"Resampled Marine DataFrame\"] = process_datetime_column(tables[\"Marine DataFrame\"], column='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Marine Data for {station_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"🔁 Processing and resampling weather data for station {station_id}...\")\n",
    "        tables[\"Resampled Meteo DataFrame\"] = process_datetime_column(tables[\"Meteo DataFrame\"], column='date')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Meteo Data for {station_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTOCONVERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Processing Marine Data Conversion for station 41008...\n",
      "🔁 Processing Meteo Data Conversion for station 41008...\n",
      "🔁 Processing Marine Data Conversion for station 41044...\n",
      "🔁 Processing Meteo Data Conversion for station 41044...\n",
      "🔁 Processing Marine Data Conversion for station 42001...\n",
      "🔁 Processing Meteo Data Conversion for station 42001...\n",
      "🔁 Processing Marine Data Conversion for station 42002...\n",
      "🔁 Processing Meteo Data Conversion for station 42002...\n",
      "🔁 Processing Marine Data Conversion for station 42012...\n",
      "🔁 Processing Meteo Data Conversion for station 42012...\n",
      "🔁 Processing Marine Data Conversion for station 42036...\n",
      "🔁 Processing Meteo Data Conversion for station 42036...\n",
      "🔁 Processing Marine Data Conversion for station 42056...\n",
      "🔁 Processing Meteo Data Conversion for station 42056...\n",
      "🔁 Processing Marine Data Conversion for station 42058...\n",
      "🔁 Processing Meteo Data Conversion for station 42058...\n",
      "🔁 Processing Marine Data Conversion for station 44020...\n",
      "🔁 Processing Meteo Data Conversion for station 44020...\n",
      "🔁 Processing Marine Data Conversion for station 44025...\n",
      "🔁 Processing Meteo Data Conversion for station 44025...\n",
      "🔁 Processing Marine Data Conversion for station 44027...\n",
      "🔁 Processing Meteo Data Conversion for station 44027...\n",
      "🔁 Processing Marine Data Conversion for station 44065...\n",
      "🔁 Processing Meteo Data Conversion for station 44065...\n",
      "🔁 Processing Marine Data Conversion for station 46001...\n",
      "🔁 Processing Meteo Data Conversion for station 46001...\n",
      "🔁 Processing Marine Data Conversion for station 46006...\n",
      "🔁 Processing Meteo Data Conversion for station 46006...\n",
      "🔁 Processing Marine Data Conversion for station 46014...\n",
      "🔁 Processing Meteo Data Conversion for station 46014...\n",
      "🔁 Processing Marine Data Conversion for station 46022...\n",
      "🔁 Processing Meteo Data Conversion for station 46022...\n",
      "🔁 Processing Marine Data Conversion for station 46025...\n",
      "🔁 Processing Meteo Data Conversion for station 46025...\n",
      "🔁 Processing Marine Data Conversion for station 46027...\n",
      "🔁 Processing Meteo Data Conversion for station 46027...\n",
      "🔁 Processing Marine Data Conversion for station 46029...\n",
      "🔁 Processing Meteo Data Conversion for station 46029...\n",
      "🔁 Processing Marine Data Conversion for station 46053...\n",
      "🔁 Processing Meteo Data Conversion for station 46053...\n",
      "🔁 Processing Marine Data Conversion for station 46069...\n",
      "🔁 Processing Meteo Data Conversion for station 46069...\n",
      "🔁 Processing Marine Data Conversion for station 46071...\n",
      "🔁 Processing Meteo Data Conversion for station 46071...\n",
      "🔁 Processing Marine Data Conversion for station 46072...\n",
      "🔁 Processing Meteo Data Conversion for station 46072...\n",
      "🔁 Processing Marine Data Conversion for station 46078...\n",
      "🔁 Processing Meteo Data Conversion for station 46078...\n",
      "🔁 Processing Marine Data Conversion for station 46084...\n",
      "🔁 Processing Meteo Data Conversion for station 46084...\n",
      "🔁 Processing Marine Data Conversion for station 46086...\n",
      "🔁 Processing Meteo Data Conversion for station 46086...\n",
      "🔁 Processing Marine Data Conversion for station 46087...\n",
      "🔁 Processing Meteo Data Conversion for station 46087...\n",
      "🔁 Processing Marine Data Conversion for station 46088...\n",
      "🔁 Processing Meteo Data Conversion for station 46088...\n",
      "🔁 Processing Marine Data Conversion for station 51000...\n",
      "🔁 Processing Meteo Data Conversion for station 51000...\n",
      "🔁 Processing Marine Data Conversion for station 51001...\n",
      "🔁 Processing Meteo Data Conversion for station 51001...\n",
      "🔁 Processing Marine Data Conversion for station 51002...\n",
      "🔁 Processing Meteo Data Conversion for station 51002...\n",
      "🔁 Processing Marine Data Conversion for station BURL1...\n",
      "🔁 Processing Meteo Data Conversion for station BURL1...\n",
      "🔁 Processing Marine Data Conversion for station FFIA2...\n",
      "🔁 Processing Meteo Data Conversion for station FFIA2...\n",
      "🔁 Processing Marine Data Conversion for station LONF1...\n",
      "🔁 Processing Meteo Data Conversion for station LONF1...\n",
      "🔁 Processing Marine Data Conversion for station MDRM1...\n",
      "🔁 Processing Meteo Data Conversion for station MDRM1...\n",
      "🔁 Processing Marine Data Conversion for station MRKA2...\n",
      "🔁 Processing Meteo Data Conversion for station MRKA2...\n",
      "🔁 Processing Marine Data Conversion for station POTA2...\n",
      "🔁 Processing Meteo Data Conversion for station POTA2...\n",
      "🔁 Processing Marine Data Conversion for station SANF1...\n",
      "🔁 Processing Meteo Data Conversion for station SANF1...\n",
      "🔁 Processing Marine Data Conversion for station SBIO1...\n",
      "🔁 Processing Meteo Data Conversion for station SBIO1...\n"
     ]
    }
   ],
   "source": [
    "# Conversion automatique des données\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"🔁 Processing Marine Data Conversion for station {station_id}...\")\n",
    "        tables[\"Autoconverted Marine DataFrame\"] = auto_convert(tables[\"Resampled Marine DataFrame\"])\n",
    "        marine_data_conversion += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Marine Data Conversion Failed for {station_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"🔁 Processing Meteo Data Conversion for station {station_id}...\")\n",
    "        tables[\"Autoconverted Meteo DataFrame\"] = auto_convert(tables[\"Resampled Meteo DataFrame\"])\n",
    "        meteo_data_conversion += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Meteo Data Conversion Failed for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                      int64\n",
       "Datetime                  datetime64[ns, UTC]\n",
       "temperature_2m                        float64\n",
       "relative_humidity_2m                  float64\n",
       "dew_point_2m                          float64\n",
       "precipitation                         float64\n",
       "rain                                  float64\n",
       "showers                               float64\n",
       "pressure_msl                          float64\n",
       "surface_pressure                      float64\n",
       "cloud_cover                           float64\n",
       "cloud_cover_low                       float64\n",
       "cloud_cover_mid                       float64\n",
       "cloud_cover_high                      float64\n",
       "visibility                            float64\n",
       "wind_speed_10m                        float64\n",
       "soil_temperature_0cm                  float64\n",
       "soil_moisture_0_to_1cm                float64\n",
       "is_day                                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buoys_datas[\"42058\"][\"Autoconverted Meteo DataFrame\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDING COORDINATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Coordinates (Lat/Lon) added for station 41008.\n",
      "🌐 Coordinates (Lat/Lon) added for station 41044.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42002.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42012.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42036.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42056.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42058.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44020.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44025.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44027.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44065.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46006.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46014.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46022.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46025.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46027.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46029.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46053.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46069.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46071.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46072.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46078.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46084.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46086.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46087.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46088.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51000.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51002.\n",
      "🌐 Coordinates (Lat/Lon) added for station BURL1.\n",
      "🌐 Coordinates (Lat/Lon) added for station FFIA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station LONF1.\n",
      "🌐 Coordinates (Lat/Lon) added for station MDRM1.\n",
      "🌐 Coordinates (Lat/Lon) added for station MRKA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station POTA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station SANF1.\n",
      "🌐 Coordinates (Lat/Lon) added for station SBIO1.\n"
     ]
    }
   ],
   "source": [
    "# Ajout des coordonnées\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        tables[\"Autoconverted Marine DataFrame\"][\"Lat\"] = tables[\"Lat\"]\n",
    "        tables[\"Autoconverted Marine DataFrame\"][\"Lon\"] = tables[\"Lon\"]\n",
    "        print(f\"🌐 Coordinates (Lat/Lon) added for station {station_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding coordinates for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAIRS DATAFRAMES FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Merging marine and weather data for station 41008...\n",
      "🔗 Merging marine and weather data for station 41044...\n",
      "🔗 Merging marine and weather data for station 42001...\n",
      "🔗 Merging marine and weather data for station 42002...\n",
      "🔗 Merging marine and weather data for station 42012...\n",
      "🔗 Merging marine and weather data for station 42036...\n",
      "🔗 Merging marine and weather data for station 42056...\n",
      "🔗 Merging marine and weather data for station 42058...\n",
      "🔗 Merging marine and weather data for station 44020...\n",
      "🔗 Merging marine and weather data for station 44025...\n",
      "🔗 Merging marine and weather data for station 44027...\n",
      "🔗 Merging marine and weather data for station 44065...\n",
      "🔗 Merging marine and weather data for station 46001...\n",
      "🔗 Merging marine and weather data for station 46006...\n",
      "🔗 Merging marine and weather data for station 46014...\n",
      "🔗 Merging marine and weather data for station 46022...\n",
      "🔗 Merging marine and weather data for station 46025...\n",
      "🔗 Merging marine and weather data for station 46027...\n",
      "🔗 Merging marine and weather data for station 46029...\n",
      "🔗 Merging marine and weather data for station 46053...\n",
      "🔗 Merging marine and weather data for station 46069...\n",
      "🔗 Merging marine and weather data for station 46071...\n",
      "🔗 Merging marine and weather data for station 46072...\n",
      "🔗 Merging marine and weather data for station 46078...\n",
      "🔗 Merging marine and weather data for station 46084...\n",
      "🔗 Merging marine and weather data for station 46086...\n",
      "🔗 Merging marine and weather data for station 46087...\n",
      "🔗 Merging marine and weather data for station 46088...\n",
      "🔗 Merging marine and weather data for station 51000...\n",
      "🔗 Merging marine and weather data for station 51001...\n",
      "🔗 Merging marine and weather data for station 51002...\n",
      "🔗 Merging marine and weather data for station BURL1...\n",
      "🔗 Merging marine and weather data for station FFIA2...\n",
      "🔗 Merging marine and weather data for station LONF1...\n",
      "🔗 Merging marine and weather data for station MDRM1...\n",
      "🔗 Merging marine and weather data for station MRKA2...\n",
      "🔗 Merging marine and weather data for station POTA2...\n",
      "🔗 Merging marine and weather data for station SANF1...\n",
      "🔗 Merging marine and weather data for station SBIO1...\n"
     ]
    }
   ],
   "source": [
    "# Fusion des DataFrames\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"🔗 Merging marine and weather data for station {station_id}...\")\n",
    "        df_merged = pd.merge(\n",
    "            tables[\"Autoconverted Marine DataFrame\"], tables[\"Autoconverted Meteo DataFrame\"], on='Datetime', how='inner'\n",
    "        )\n",
    "        tables[\"Merged Dataframe\"] = df_merged\n",
    "        number_merged_data += df_merged.shape[0]\n",
    "        list_silver_merged_df.append(df_merged)\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging data for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                           1  (int64)\n",
      "wind_direction                 240.0  (float64)\n",
      "wind_speed                     5.0  (float64)\n",
      "wind_gust                      6.0  (float64)\n",
      "wave_height                    0.7  (float64)\n",
      "dominant_wave_period           4.0  (float64)\n",
      "average_wave_period            3.7  (float64)\n",
      "dominant_wave_direction        218.0  (float64)\n",
      "pressure                       1020.3  (float64)\n",
      "air_temperature                14.1  (float64)\n",
      "water_temperature              15.3  (float64)\n",
      "dewpoint                       10.4  (float64)\n",
      "3hr_pressure_tendency          0.0  (float64)\n",
      "Datetime                       2025-03-22 11:00:00+00:00  (datetime64[ns, UTC])\n",
      "Station ID                     41008  (int64)\n",
      "Lat                            31.40N  (object)\n",
      "Lon                            80.87W  (object)\n",
      "id_y                           2220  (int64)\n",
      "temperature_2m                 5.110000133514404  (float64)\n",
      "relative_humidity_2m           56.0  (float64)\n",
      "dew_point_2m                   -2.9600000381469727  (float64)\n",
      "precipitation                  0.0  (float64)\n",
      "rain                           0.0  (float64)\n",
      "showers                        0.0  (float64)\n",
      "pressure_msl                   1003.7000122070312  (float64)\n",
      "surface_pressure               979.2899780273438  (float64)\n",
      "cloud_cover                    0.0  (float64)\n",
      "cloud_cover_low                0.0  (float64)\n",
      "cloud_cover_mid                0.0  (float64)\n",
      "cloud_cover_high               0.0  (float64)\n",
      "visibility                     34300.0  (float64)\n",
      "wind_speed_10m                 22.06999969482422  (float64)\n",
      "soil_temperature_0cm           6.739999771118164  (float64)\n",
      "soil_moisture_0_to_1cm         0.2800000011920929  (float64)\n",
      "is_day                         0.0  (float64)\n"
     ]
    }
   ],
   "source": [
    "show_first_row(buoys_datas[\"41008\"][\"Merged Dataframe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                                    0   / 6973\n",
      "wind_direction                          0   / 6973\n",
      "wind_speed                              0   / 6973\n",
      "wind_gust                               0   / 6973\n",
      "wave_height                             0   / 6973\n",
      "dominant_wave_period                    0   / 6973\n",
      "average_wave_period                     0   / 6973\n",
      "dominant_wave_direction                 0   / 6973\n",
      "pressure                                0   / 6973\n",
      "air_temperature                         0   / 6973\n",
      "water_temperature                       0   / 6973\n",
      "dewpoint                                0   / 6973\n",
      "3hr_pressure_tendency                   0   / 6973\n",
      "Datetime                                0   / 6973\n",
      "Station ID                              0   / 6973\n",
      "Lat                                     0   / 6973\n",
      "Lon                                     0   / 6973\n",
      "id_y                                    0   / 6973\n",
      "temperature_2m                          0   / 6973\n",
      "relative_humidity_2m                    0   / 6973\n",
      "dew_point_2m                            0   / 6973\n",
      "precipitation                           0   / 6973\n",
      "rain                                    0   / 6973\n",
      "showers                                 0   / 6973\n",
      "pressure_msl                            0   / 6973\n",
      "surface_pressure                        0   / 6973\n",
      "cloud_cover                             0   / 6973\n",
      "cloud_cover_low                         0   / 6973\n",
      "cloud_cover_mid                         0   / 6973\n",
      "cloud_cover_high                        0   / 6973\n",
      "visibility                              0   / 6973\n",
      "wind_speed_10m                          0   / 6973\n",
      "soil_temperature_0cm                    0   / 6973\n",
      "soil_moisture_0_to_1cm                  0   / 6973\n",
      "is_day                                  0   / 6973\n"
     ]
    }
   ],
   "source": [
    "show_null_counts(buoys_datas[\"41008\"][\"Merged Dataframe\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating all DataFrames into a Final one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔀 Merging all DataFrames into a final DataFrame...\n",
      "📝 Final merged DataFrame size: (228592, 35)\n",
      "\n",
      "⭐🏆 Processing complete!\n",
      "🔢 Total stations processed: 39\n",
      "Marine data rows collected = 0\n",
      "Meteo data rows collected = 0\n",
      "Marine Data Successfully Converted: 39\n",
      "Meteo Data Successfully Converted: 39\n",
      "Total Number of merged rows: 228592\n",
      "Final DataFrame rows number: 228592\n",
      "❌ Number of failed stations: 0\n"
     ]
    }
   ],
   "source": [
    "# Fusion finale de tous les DataFrames\n",
    "try:\n",
    "    print(\"🔀 Merging all DataFrames into a final DataFrame...\")\n",
    "    dataframes_to_concat = [tables[\"Merged Dataframe\"] for tables in buoys_datas.values()]\n",
    "    df_final = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "    print(f\"📝 Final merged DataFrame size: {df_final.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during final merge: {e}\")\n",
    "    df_final = None\n",
    "\n",
    "# Résumé final\n",
    "print(\"\\n⭐🏆 Processing complete!\")\n",
    "print(f\"🔢 Total stations processed: {len(buoys_datas)}\")\n",
    "print(f\"Marine data rows collected = {number_marine_data}\\nMeteo data rows collected = {number_meteo_data}\")\n",
    "print(f\"Marine Data Successfully Converted: {marine_data_conversion}\")\n",
    "print(f\"Meteo Data Successfully Converted: {meteo_data_conversion}\")\n",
    "\n",
    "if df_final is not None and not df_final.empty:\n",
    "    print(f\"Total Number of merged rows: {number_merged_data}\")\n",
    "    print(f\"Final DataFrame rows number: {df_final.shape[0]}\")\n",
    "else:\n",
    "    print(\"The DataFrame is either None or empty.\")\n",
    "\n",
    "print(f\"❌ Number of failed stations: {len(list_failed_dfs)}\")\n",
    "if list_failed_dfs:\n",
    "    print(f\"⚠️ Failed stations: {', '.join(map(str, list_failed_dfs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                           1  (int64)\n",
      "wind_direction                 240.0  (float64)\n",
      "wind_speed                     5.0  (float64)\n",
      "wind_gust                      6.0  (float64)\n",
      "wave_height                    0.7  (float64)\n",
      "dominant_wave_period           4.0  (float64)\n",
      "average_wave_period            3.7  (float64)\n",
      "dominant_wave_direction        218.0  (float64)\n",
      "pressure                       1020.3  (float64)\n",
      "air_temperature                14.1  (float64)\n",
      "water_temperature              15.3  (float64)\n",
      "dewpoint                       10.4  (float64)\n",
      "3hr_pressure_tendency          0.0  (float64)\n",
      "Datetime                       2025-03-22 11:00:00+00:00  (datetime64[ns, UTC])\n",
      "Station ID                     41008.0  (float64)\n",
      "Lat                            31.40N  (object)\n",
      "Lon                            80.87W  (object)\n",
      "id_y                           2220  (int64)\n",
      "temperature_2m                 5.110000133514404  (float64)\n",
      "relative_humidity_2m           56.0  (float64)\n",
      "dew_point_2m                   -2.9600000381469727  (float64)\n",
      "precipitation                  0.0  (float64)\n",
      "rain                           0.0  (float64)\n",
      "showers                        0.0  (float64)\n",
      "pressure_msl                   1003.7000122070312  (float64)\n",
      "surface_pressure               979.2899780273438  (float64)\n",
      "cloud_cover                    0.0  (float64)\n",
      "cloud_cover_low                0.0  (float64)\n",
      "cloud_cover_mid                0.0  (float64)\n",
      "cloud_cover_high               0.0  (float64)\n",
      "visibility                     34300.0  (float64)\n",
      "wind_speed_10m                 22.06999969482422  (float64)\n",
      "soil_temperature_0cm           6.739999771118164  (float64)\n",
      "soil_moisture_0_to_1cm         0.2800000011920929  (float64)\n",
      "is_day                         0.0  (float64)\n"
     ]
    }
   ],
   "source": [
    "show_first_row(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                                    0   / 170723\n",
      "Wind Direction (°)                      0   / 170723\n",
      "Wind Speed (km/h)                       0   / 170723\n",
      "Wind Gusts (km/h)                       0   / 170723\n",
      "Wave Height (m)                         0   / 170723\n",
      "dominant_wave_period                    0   / 170723\n",
      "Average Wave Period (s)                 0   / 170723\n",
      "Dominant Wave Direction (°)             0   / 170723\n",
      "Pressure (hPA)                          0   / 170723\n",
      "Air T°                                  0   / 170723\n",
      "Water T°                                0   / 170723\n",
      "dewpoint                                0   / 170723\n",
      "3hr_pressure_tendency                   0   / 170723\n",
      "Datetime                                0   / 170723\n",
      "Station ID                              0   / 170723\n",
      "Lat                                     0   / 170723\n",
      "Lon                                     0   / 170723\n",
      "id_y                                    0   / 170723\n",
      "T°(C°)                                  0   / 170723\n",
      "Relative Humidity (%)                   0   / 170723\n",
      "Dew Point (°C)                          0   / 170723\n",
      "Precipitation (mm)                      0   / 170723\n",
      "rain                                    0   / 170723\n",
      "showers                                 0   / 170723\n",
      " Sea Level Pressure (hPa)               0   / 170723\n",
      "surface_pressure                        0   / 170723\n",
      "cloud_cover                             0   / 170723\n",
      "Low Clouds (%)                          0   / 170723\n",
      "Middle Clouds (%)                       0   / 170723\n",
      "High Clouds (%)                         0   / 170723\n",
      " Visibility (%)                         0   / 170723\n",
      "wind_speed_10m                          0   / 170723\n",
      "is_day                                  0   / 170723\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_final.dropna().round(2)\n",
    "show_null_counts(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Aucune colonne à renommer pour ce spécification : {'temperature_2m': 'T°(C°)', 'relative_humidity_2m': 'Relative Humidity (%)', 'dew_point_2m': 'Dew Point (°C)', 'precipitation': 'Precipitation (mm)', 'pressure_msl': ' Sea Level Pressure (hPa)', 'cloud_cover_low': 'Low Clouds (%)', 'cloud_cover_mid': 'Middle Clouds (%)', 'cloud_cover_high': 'High Clouds (%)', 'visibility': ' Visibility (%)', 'wind_direction': 'Wind Direction (°)', 'wind_speed': 'Wind Speed (km/h)', 'wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)', 'average_wave_period': 'Average Wave Period (s)', 'dominant_wave_direction': 'Dominant Wave Direction (°)', 'pressure': 'Pressure (hPA)', 'air_temperature': 'Air T°', 'water_temperature': 'Water T°'}\n",
      "Colonne 'soil_temperature_0cm' Non Trouvée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'id_x' Non Trouvée\n",
      "Colonne 'id_y' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Non Trouvée\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Wind Direction (°)', 'Wind Speed (km/h)', 'Wind Gusts (km/h)',\n",
       "       'Wave Height (m)', 'dominant_wave_period', 'Average Wave Period (s)',\n",
       "       'Dominant Wave Direction (°)', 'Pressure (hPA)', 'Air T°', 'Water T°',\n",
       "       'dewpoint', '3hr_pressure_tendency', 'Datetime', 'Station ID', 'Lat',\n",
       "       'Lon', 'T°(C°)', 'Relative Humidity (%)', 'Dew Point (°C)',\n",
       "       'Precipitation (mm)', ' Sea Level Pressure (hPa)', 'surface_pressure',\n",
       "       'cloud_cover', 'Low Clouds (%)', 'Middle Clouds (%)', 'High Clouds (%)',\n",
       "       ' Visibility (%)', 'wind_speed_10m', 'is_day', 'Daytime', 'Month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_rename={'temperature_2m': 'T°(C°)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (°C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (%)',  'wind_direction': 'Wind Direction (°)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (°)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air T°','water_temperature': 'Water T°'}\n",
    "\n",
    "df_cleaned = rename_columns(df_cleaned, col_to_rename)\n",
    "df_cleaned = drop_columns_if_exist(df_cleaned,['soil_temperature_0cm','rain', 'showers', 'is_day', 'id_x', 'id_y','soil_moisture_0_to_1cm'])\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                           1  (int64)\n",
      "Wind Direction (°)             240.0  (float64)\n",
      "Wind Speed (km/h)              5.0  (float64)\n",
      "Wind Gusts (km/h)              6.0  (float64)\n",
      "Wave Height (m)                0.7  (float64)\n",
      "dominant_wave_period           4.0  (float64)\n",
      "Average Wave Period (s)        3.7  (float64)\n",
      "Dominant Wave Direction (°)    218.0  (float64)\n",
      "Pressure (hPA)                 1020.3  (float64)\n",
      "Air T°                         14.1  (float64)\n",
      "Water T°                       15.3  (float64)\n",
      "dewpoint                       10.4  (float64)\n",
      "3hr_pressure_tendency          0.0  (float64)\n",
      "Datetime                       2025-03-22 11:00:00+00:00  (datetime64[ns, UTC])\n",
      "Station ID                     41008  (int64)\n",
      "Lat                            31.40N  (object)\n",
      "Lon                            80.87W  (object)\n",
      "id_y                           2220  (int64)\n",
      "T°(C°)                         5.11  (float64)\n",
      "Relative Humidity (%)          56.0  (float64)\n",
      "Dew Point (°C)                 -2.96  (float64)\n",
      "Precipitation (mm)             0.0  (float64)\n",
      "rain                           0.0  (float64)\n",
      "showers                        0.0  (float64)\n",
      " Sea Level Pressure (hPa)      1003.7  (float64)\n",
      "surface_pressure               979.29  (float64)\n",
      "cloud_cover                    0.0  (float64)\n",
      "Low Clouds (%)                 0.0  (float64)\n",
      "Middle Clouds (%)              0.0  (float64)\n",
      "High Clouds (%)                0.0  (float64)\n",
      " Visibility (%)                34300.0  (float64)\n",
      "wind_speed_10m                 22.07  (float64)\n",
      "is_day                         0.0  (float64)\n",
      "Daytime                        Morning  (object)\n",
      "Month                          3  (int64)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned[['Daytime', 'Month']] = df_cleaned['Datetime'].apply(lambda x: get_day_time(x)).apply(pd.Series)\n",
    "df_cleaned[\"Station ID\"] = df_cleaned[\"Station ID\"].astype(int)\n",
    "show_first_row(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dew Point (°C)</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>Air T°</th>\n",
       "      <th>T°(C°)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.96</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.07</td>\n",
       "      <td>14.1</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.96</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.07</td>\n",
       "      <td>14.1</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.96</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.07</td>\n",
       "      <td>14.2</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.35</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.81</td>\n",
       "      <td>14.3</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.35</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.81</td>\n",
       "      <td>14.3</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dew Point (°C)  dewpoint  Wind Speed (km/h)  wind_speed_10m  Air T°  T°(C°)\n",
       "0           -2.96      10.4                5.0           22.07    14.1    5.11\n",
       "1           -2.96      10.5                6.0           22.07    14.1    5.11\n",
       "2           -2.96      10.9                6.0           22.07    14.2    5.11\n",
       "3           -3.35      10.9                6.0           25.81    14.3    5.76\n",
       "4           -3.35      11.1                6.0           25.81    14.3    5.76"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_comparing = df_cleaned[['Dew Point (°C)', 'dewpoint', 'Wind Speed (km/h)', 'wind_speed_10m','Air T°','T°(C°)']]\n",
    "df_cleaned_comparing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{lat},{lon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:974\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\json\\decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\json\\decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Effectuer un nouvel appel si les 2 heures sont écoulées\u001b[39;00m\n\u001b[32m     30\u001b[39m     response = requests.get(url_last_month)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     vc_meteo_data = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     last_call_time = time.time()  \u001b[38;5;66;03m# Mettre à jour l'heure du dernier appel\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:978\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "vc_api_key_path = r\"C:\\Users\\f.gionnane\\Documents\\Data Engineering\\Credentials\\visual_crossing_weather_api.json\"\n",
    "\n",
    "with open(vc_api_key_path, 'r') as file:\n",
    "    content = json.load(file)\n",
    "    vc_api_key = content[\"api_key\"]\n",
    "\n",
    "df_42058 = df_cleaned[df_cleaned[\"Station ID\"]==42058]\n",
    "Lat = df_42058[\"Lat\"].iloc[0]  # Récupérer la première valeur de la colonne \"Lat\"\n",
    "Lon = df_42058[\"Lon\"].iloc[0]  # Récupérer la première valeur de la colonne \"Lon\"\n",
    "\n",
    "lat, lon = convert_coordinates(Lat, Lon)\n",
    "\n",
    "# Définition des dates dynamiques\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")  # Hier pour éviter les données incomplètes d'aujourd'hui\n",
    "start_date = (datetime.now() - timedelta(days=31)).strftime(\"%Y-%m-%d\")  # 31 jours avant aujourd'hui\n",
    "last_call_time = None\n",
    "vc_meteo_data = None\n",
    "\n",
    "# Construction de l'URL\n",
    "url_last_month = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{lat},{lon}/{start_date}/{today}?unitGroup=metric&key={vc_api_key}&contentType=json\"\n",
    "\n",
    "# Vérifier si 2 heures se sont écoulées depuis le dernier appel\n",
    "if last_call_time and (time.time() - last_call_time) < 20 * 60  * 60:\n",
    "# = 2 * MIN * SEC\n",
    "    print(\"Too soon to make another request. Returning previous response.\")\n",
    "\n",
    "    response = {'status_code': 200, 'data': vc_meteo_data}  # Retourner le dernier résultat\n",
    "else:\n",
    "    # Effectuer un nouvel appel si les 2 heures sont écoulées\n",
    "    response = requests.get(url_last_month)\n",
    "    vc_meteo_data = response.json()\n",
    "    last_call_time = time.time()  # Mettre à jour l'heure du dernier appel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:974\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\json\\decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\json\\decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Récupérer les données de l'API\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vc_meteo_data = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(vc_meteo_data)  \u001b[38;5;66;03m# Vérifiez les données récupérées\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:978\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Récupérer les données de l'API\n",
    "vc_meteo_data = response.json()\n",
    "print(vc_meteo_data)  # Vérifiez les données récupérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>datetimeEpoch</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>humidity</th>\n",
       "      <th>dew</th>\n",
       "      <th>precip</th>\n",
       "      <th>precipprob</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>...</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>severerisk</th>\n",
       "      <th>conditions</th>\n",
       "      <th>icon</th>\n",
       "      <th>stations</th>\n",
       "      <th>source</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1742619600</td>\n",
       "      <td>26.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>86.71</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>[remote]</td>\n",
       "      <td>obs</td>\n",
       "      <td>[{'datetime': '2025-03-22', 'datetimeEpoch': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   datetime  datetimeEpoch  temp  feelslike  humidity   dew  precip  \\\n",
       "0  00:00:00     1742619600  26.7       26.7     86.71  24.3     0.0   \n",
       "\n",
       "   precipprob  snow snowdepth  ... cloudcover  solarradiation  solarenergy  \\\n",
       "0         0.0   0.0      None  ...      100.0             0.0          0.0   \n",
       "\n",
       "   uvindex  severerisk  conditions    icon  stations  source  \\\n",
       "0      0.0        30.0    Overcast  cloudy  [remote]     obs   \n",
       "\n",
       "                                                days  \n",
       "0  [{'datetime': '2025-03-22', 'datetimeEpoch': 1...  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normaliser les données JSON en DataFrame\n",
    "df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# Afficher la première ligne des données\n",
    "df_vc_meteo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion du timestamp en datetime\n",
    "df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les dates de filtrage pour les 30 derniers jours\n",
    "today = datetime.now()\n",
    "thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "# Convertir les dates en format YYYY-MM-DD\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_vc_meteo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Filtrer les données des 30 derniers jours de df_vc_meteo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_test_last_month = \u001b[43mdf_vc_meteo\u001b[49m[[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHour\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwindspeed\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m      3\u001b[39m df_test_last_month = df_test_last_month[(df_test_last_month[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m] >= thirty_days_ago_str) & \n\u001b[32m      4\u001b[39m                                         (df_test_last_month[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m] <= today_str)]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Ajouter les colonnes Date et Hour à df_42058 (si ce n'est pas déjà fait)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_vc_meteo' is not defined"
     ]
    }
   ],
   "source": [
    "# Filtrer les données des 30 derniers jours de df_vc_meteo\n",
    "df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "                                        (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# Ajouter les colonnes Date et Hour à df_42058 (si ce n'est pas déjà fait)\n",
    "df_42058['Date'] = df_42058['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_42058['Hour'] = df_42058['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# Filtrer les données des 30 derniers jours dans df_42058\n",
    "df_42058_last_month = df_42058[(df_42058['Date'] >= thirty_days_ago_str) & \n",
    "                                (df_42058['Date'] <= today_str)]\n",
    "\n",
    "# Fusionner les deux DataFrames sur Date et Hour\n",
    "df_merged = df_test_last_month.merge(df_42058_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "                                     on=['Date', 'Hour'], \n",
    "                                     how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>MongoDB</th>\n",
       "      <th>Cassandra</th>\n",
       "      <th>Firebase Firestore</th>\n",
       "      <th>Redis</th>\n",
       "      <th>Couchbase</th>\n",
       "      <th>Amazon DynamoDB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Model</td>\n",
       "      <td>Document-based (BSON)</td>\n",
       "      <td>Wide-column store (keyspace/column-family)</td>\n",
       "      <td>Document-based (JSON)</td>\n",
       "      <td>Key-value store (in-memory)</td>\n",
       "      <td>Document &amp; key-value store (JSON)</td>\n",
       "      <td>Key-value &amp; document store (JSON)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scalability</td>\n",
       "      <td>Horizontal scaling, sharding</td>\n",
       "      <td>Excellent horizontal scalability, designed for...</td>\n",
       "      <td>Horizontal scaling (via Google Cloud)</td>\n",
       "      <td>Horizontal scalability (via Redis Cluster)</td>\n",
       "      <td>Horizontal scaling via clusters</td>\n",
       "      <td>Fully managed horizontal scaling, ideal for hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Performance</td>\n",
       "      <td>Good for read-heavy workloads, slower writes</td>\n",
       "      <td>Excellent for write-heavy workloads</td>\n",
       "      <td>Excellent for mobile apps, scalable</td>\n",
       "      <td>Extremely fast (in-memory)</td>\n",
       "      <td>High-performance, low-latency</td>\n",
       "      <td>Low-latency, high-throughput (ideal for high-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Real-time Support</td>\n",
       "      <td>Limited real-time support (with change streams)</td>\n",
       "      <td>Not built for real-time data</td>\n",
       "      <td>Built-in real-time synchronization (e.g., Fire...</td>\n",
       "      <td>High real-time support (pub/sub via channels)</td>\n",
       "      <td>Good with N1QL queries and sync features</td>\n",
       "      <td>Good real-time support via DynamoDB Streams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consistency</td>\n",
       "      <td>Tunable consistency (eventual or strong)</td>\n",
       "      <td>Eventual consistency</td>\n",
       "      <td>Strong consistency</td>\n",
       "      <td>Eventual consistency (with persistence)</td>\n",
       "      <td>Tunable consistency (via N1QL queries)</td>\n",
       "      <td>Strong consistency (default)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ease of Use</td>\n",
       "      <td>Easy to use, rich documentation</td>\n",
       "      <td>Steeper learning curve, complex setup</td>\n",
       "      <td>Very easy to use, ideal for mobile games</td>\n",
       "      <td>Easy to use, focused on caching and speed</td>\n",
       "      <td>Moderate learning curve, powerful queries</td>\n",
       "      <td>Easy to use, fully managed solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Integration with Unity</td>\n",
       "      <td>Available SDKs and plugins (third-party)</td>\n",
       "      <td>No official SDK, requires custom setup</td>\n",
       "      <td>Direct SDK integration with Unity (Firebase Un...</td>\n",
       "      <td>Unity integration via third-party packages</td>\n",
       "      <td>SDKs available for Unity, but might need confi...</td>\n",
       "      <td>SDK available for Unity (AWS SDK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Integration with C#</td>\n",
       "      <td>C# libraries available</td>\n",
       "      <td>Integration via REST API</td>\n",
       "      <td>Native C# SDK for Firestore</td>\n",
       "      <td>Integration via third-party C# libraries</td>\n",
       "      <td>C# SDK available for integration</td>\n",
       "      <td>C# SDK for DynamoDB available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cloud/On-Prem Support</td>\n",
       "      <td>Both (MongoDB Atlas for cloud)</td>\n",
       "      <td>Primarily for on-prem, but cloud options avail...</td>\n",
       "      <td>Fully managed cloud solution (Google Cloud)</td>\n",
       "      <td>Managed via Redis Cloud or on-prem setup</td>\n",
       "      <td>Both (Couchbase Cloud for cloud)</td>\n",
       "      <td>Fully managed cloud (AWS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Use Case Suitability</td>\n",
       "      <td>General-purpose, complex queries (ideal for us...</td>\n",
       "      <td>High-throughput applications (ideal for large-...</td>\n",
       "      <td>Real-time user data syncing, especially for mo...</td>\n",
       "      <td>Caching and real-time session data</td>\n",
       "      <td>High-availability, high-performance, mobile/we...</td>\n",
       "      <td>Ideal for highly scalable games (leaderboards,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cost</td>\n",
       "      <td>Free tier available, pay-as-you-go for cloud</td>\n",
       "      <td>Free for small setups, pay-as-you-go for cloud</td>\n",
       "      <td>Free tier available, pay-as-you-go for cloud</td>\n",
       "      <td>Free tier, pay-as-you-go for Redis Cloud</td>\n",
       "      <td>Free tier, pay-as-you-go for cloud services</td>\n",
       "      <td>Pay-as-you-go based on usage (AWS pricing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Support for Unity 3D SDK</td>\n",
       "      <td>Third-party SDKs, good integration</td>\n",
       "      <td>No official SDK, requires manual integration</td>\n",
       "      <td>Official SDK for Unity available</td>\n",
       "      <td>Third-party SDK for Unity</td>\n",
       "      <td>Unity SDK available, needs configuration</td>\n",
       "      <td>Official Unity SDK available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Player Session Management</td>\n",
       "      <td>Flexible player session storage</td>\n",
       "      <td>Not specifically designed for session management</td>\n",
       "      <td>Real-time session management integrated (Fireb...</td>\n",
       "      <td>Great for managing sessions via Redis channels</td>\n",
       "      <td>Session management with persistence possible i...</td>\n",
       "      <td>Handles sessions well via DynamoDB Streams and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Real-time Latency Management for MMORPGs</td>\n",
       "      <td>Moderate latency support</td>\n",
       "      <td>High latency due to replication</td>\n",
       "      <td>Excellent real-time support via Firebase SDK</td>\n",
       "      <td>Very low latency (ideal for fast games)</td>\n",
       "      <td>Good real-time updates via N1QL and sync features</td>\n",
       "      <td>Low latency, ideal for high-throughput games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Big Data Integration and Analytics</td>\n",
       "      <td>Integrates with tools like Hadoop or Spark for...</td>\n",
       "      <td>Well-suited for integration with Big Data tool...</td>\n",
       "      <td>Easy integration with Google BigQuery for anal...</td>\n",
       "      <td>Integration with real-time analytics tools (e....</td>\n",
       "      <td>Integrates with Big Data tools via SDK and API</td>\n",
       "      <td>Integrates with AWS Analytics (Redshift, EMR, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Transaction and Data Integrity</td>\n",
       "      <td>ACID transactions (via MongoDB transactions)</td>\n",
       "      <td>Limited transaction support, not ideal for com...</td>\n",
       "      <td>Simple transactions, good for mobile games</td>\n",
       "      <td>No transactions, but ensures consistency via k...</td>\n",
       "      <td>Transactions via N1QL for data consistency</td>\n",
       "      <td>ACID transactions supported via DynamoDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Real-time Data Updates for MMORPGs</td>\n",
       "      <td>Updates via change streams in MongoDB</td>\n",
       "      <td>No native support for real-time updates</td>\n",
       "      <td>Excellent real-time updates via Firestore SDK</td>\n",
       "      <td>Real-time updates via Redis Pub/Sub</td>\n",
       "      <td>Real-time updates via N1QL and Couchbase SDK</td>\n",
       "      <td>Real-time updates via DynamoDB Streams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Flexibility for Evolving Data Structures</td>\n",
       "      <td>Very flexible with unstructured data (BSON)</td>\n",
       "      <td>Less flexible for frequent schema changes</td>\n",
       "      <td>Flexible with JSON, easy to evolve via Firestore</td>\n",
       "      <td>Flexible for storing key-value data structures</td>\n",
       "      <td>Flexible with JSON and N1QL queries for comple...</td>\n",
       "      <td>Flexible with JSON and easy to evolve with Dyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Security</td>\n",
       "      <td>Secured via MongoDB Atlas, SSL, and authentica...</td>\n",
       "      <td>Security via third-party mechanisms (SSL, app-...</td>\n",
       "      <td>Secured via Firebase Authentication, data encr...</td>\n",
       "      <td>Secured via Redis Auth, SSL for connections</td>\n",
       "      <td>Secured via SSL and authentication with Couchbase</td>\n",
       "      <td>Secured with AWS KMS, SSL, and IAM for access ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Feature  \\\n",
       "0                                 Data Model   \n",
       "1                                Scalability   \n",
       "2                                Performance   \n",
       "3                          Real-time Support   \n",
       "4                                Consistency   \n",
       "5                                Ease of Use   \n",
       "6                     Integration with Unity   \n",
       "7                        Integration with C#   \n",
       "8                      Cloud/On-Prem Support   \n",
       "9                       Use Case Suitability   \n",
       "10                                      Cost   \n",
       "11                  Support for Unity 3D SDK   \n",
       "12                 Player Session Management   \n",
       "13  Real-time Latency Management for MMORPGs   \n",
       "14        Big Data Integration and Analytics   \n",
       "15            Transaction and Data Integrity   \n",
       "16        Real-time Data Updates for MMORPGs   \n",
       "17  Flexibility for Evolving Data Structures   \n",
       "18                             Data Security   \n",
       "\n",
       "                                              MongoDB  \\\n",
       "0                               Document-based (BSON)   \n",
       "1                        Horizontal scaling, sharding   \n",
       "2        Good for read-heavy workloads, slower writes   \n",
       "3     Limited real-time support (with change streams)   \n",
       "4            Tunable consistency (eventual or strong)   \n",
       "5                     Easy to use, rich documentation   \n",
       "6            Available SDKs and plugins (third-party)   \n",
       "7                              C# libraries available   \n",
       "8                      Both (MongoDB Atlas for cloud)   \n",
       "9   General-purpose, complex queries (ideal for us...   \n",
       "10       Free tier available, pay-as-you-go for cloud   \n",
       "11                 Third-party SDKs, good integration   \n",
       "12                    Flexible player session storage   \n",
       "13                           Moderate latency support   \n",
       "14  Integrates with tools like Hadoop or Spark for...   \n",
       "15       ACID transactions (via MongoDB transactions)   \n",
       "16              Updates via change streams in MongoDB   \n",
       "17        Very flexible with unstructured data (BSON)   \n",
       "18  Secured via MongoDB Atlas, SSL, and authentica...   \n",
       "\n",
       "                                            Cassandra  \\\n",
       "0          Wide-column store (keyspace/column-family)   \n",
       "1   Excellent horizontal scalability, designed for...   \n",
       "2                 Excellent for write-heavy workloads   \n",
       "3                        Not built for real-time data   \n",
       "4                                Eventual consistency   \n",
       "5               Steeper learning curve, complex setup   \n",
       "6              No official SDK, requires custom setup   \n",
       "7                            Integration via REST API   \n",
       "8   Primarily for on-prem, but cloud options avail...   \n",
       "9   High-throughput applications (ideal for large-...   \n",
       "10     Free for small setups, pay-as-you-go for cloud   \n",
       "11       No official SDK, requires manual integration   \n",
       "12   Not specifically designed for session management   \n",
       "13                    High latency due to replication   \n",
       "14  Well-suited for integration with Big Data tool...   \n",
       "15  Limited transaction support, not ideal for com...   \n",
       "16            No native support for real-time updates   \n",
       "17          Less flexible for frequent schema changes   \n",
       "18  Security via third-party mechanisms (SSL, app-...   \n",
       "\n",
       "                                   Firebase Firestore  \\\n",
       "0                               Document-based (JSON)   \n",
       "1               Horizontal scaling (via Google Cloud)   \n",
       "2                 Excellent for mobile apps, scalable   \n",
       "3   Built-in real-time synchronization (e.g., Fire...   \n",
       "4                                  Strong consistency   \n",
       "5            Very easy to use, ideal for mobile games   \n",
       "6   Direct SDK integration with Unity (Firebase Un...   \n",
       "7                         Native C# SDK for Firestore   \n",
       "8         Fully managed cloud solution (Google Cloud)   \n",
       "9   Real-time user data syncing, especially for mo...   \n",
       "10       Free tier available, pay-as-you-go for cloud   \n",
       "11                   Official SDK for Unity available   \n",
       "12  Real-time session management integrated (Fireb...   \n",
       "13       Excellent real-time support via Firebase SDK   \n",
       "14  Easy integration with Google BigQuery for anal...   \n",
       "15         Simple transactions, good for mobile games   \n",
       "16      Excellent real-time updates via Firestore SDK   \n",
       "17   Flexible with JSON, easy to evolve via Firestore   \n",
       "18  Secured via Firebase Authentication, data encr...   \n",
       "\n",
       "                                                Redis  \\\n",
       "0                         Key-value store (in-memory)   \n",
       "1          Horizontal scalability (via Redis Cluster)   \n",
       "2                          Extremely fast (in-memory)   \n",
       "3       High real-time support (pub/sub via channels)   \n",
       "4             Eventual consistency (with persistence)   \n",
       "5           Easy to use, focused on caching and speed   \n",
       "6          Unity integration via third-party packages   \n",
       "7            Integration via third-party C# libraries   \n",
       "8            Managed via Redis Cloud or on-prem setup   \n",
       "9                  Caching and real-time session data   \n",
       "10           Free tier, pay-as-you-go for Redis Cloud   \n",
       "11                          Third-party SDK for Unity   \n",
       "12     Great for managing sessions via Redis channels   \n",
       "13            Very low latency (ideal for fast games)   \n",
       "14  Integration with real-time analytics tools (e....   \n",
       "15  No transactions, but ensures consistency via k...   \n",
       "16                Real-time updates via Redis Pub/Sub   \n",
       "17     Flexible for storing key-value data structures   \n",
       "18        Secured via Redis Auth, SSL for connections   \n",
       "\n",
       "                                            Couchbase  \\\n",
       "0                   Document & key-value store (JSON)   \n",
       "1                     Horizontal scaling via clusters   \n",
       "2                       High-performance, low-latency   \n",
       "3            Good with N1QL queries and sync features   \n",
       "4              Tunable consistency (via N1QL queries)   \n",
       "5           Moderate learning curve, powerful queries   \n",
       "6   SDKs available for Unity, but might need confi...   \n",
       "7                    C# SDK available for integration   \n",
       "8                    Both (Couchbase Cloud for cloud)   \n",
       "9   High-availability, high-performance, mobile/we...   \n",
       "10        Free tier, pay-as-you-go for cloud services   \n",
       "11           Unity SDK available, needs configuration   \n",
       "12  Session management with persistence possible i...   \n",
       "13  Good real-time updates via N1QL and sync features   \n",
       "14     Integrates with Big Data tools via SDK and API   \n",
       "15         Transactions via N1QL for data consistency   \n",
       "16       Real-time updates via N1QL and Couchbase SDK   \n",
       "17  Flexible with JSON and N1QL queries for comple...   \n",
       "18  Secured via SSL and authentication with Couchbase   \n",
       "\n",
       "                                      Amazon DynamoDB  \n",
       "0                   Key-value & document store (JSON)  \n",
       "1   Fully managed horizontal scaling, ideal for hi...  \n",
       "2   Low-latency, high-throughput (ideal for high-t...  \n",
       "3         Good real-time support via DynamoDB Streams  \n",
       "4                        Strong consistency (default)  \n",
       "5                 Easy to use, fully managed solution  \n",
       "6                   SDK available for Unity (AWS SDK)  \n",
       "7                       C# SDK for DynamoDB available  \n",
       "8                           Fully managed cloud (AWS)  \n",
       "9   Ideal for highly scalable games (leaderboards,...  \n",
       "10         Pay-as-you-go based on usage (AWS pricing)  \n",
       "11                       Official Unity SDK available  \n",
       "12  Handles sessions well via DynamoDB Streams and...  \n",
       "13       Low latency, ideal for high-throughput games  \n",
       "14  Integrates with AWS Analytics (Redshift, EMR, ...  \n",
       "15           ACID transactions supported via DynamoDB  \n",
       "16             Real-time updates via DynamoDB Streams  \n",
       "17  Flexible with JSON and easy to evolve with Dyn...  \n",
       "18  Secured with AWS KMS, SSL, and IAM for access ...  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path =r\"C:\\Users\\f.gionnane\\Documents\\Data Engineering\\NoSQL_DB_comparisons.csv\"\n",
    "\n",
    "nosql_comparison = pd.read_csv(csv_path, encoding='utf-8')\n",
    "nosql_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def handle_null_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     row_count = df.shape[0]\n",
    "    \n",
    "#     # Initialisation des listes pour suivre les colonnes supprimées\n",
    "#     removed_columns = []\n",
    "#     non_numeric_columns_to_drop = []\n",
    "    \n",
    "#     # Utiliser lambda et apply() pour calculer le nombre de valeurs nulles dans chaque colonne\n",
    "#     null_counts = df.apply(lambda col: int(col.isnull().sum()))  # Calculer le nombre de NaN par colonne\n",
    "    \n",
    "#     # Condition : 1. Colonnes avec toutes les valeurs nulles ou 2. Plus de 50% de valeurs nulles et colonne non numérique\n",
    "#     columns_to_drop = null_counts[\n",
    "#         (null_counts == row_count) | \n",
    "#         ((null_counts > row_count * 0.5) & ~df.apply(lambda col: pd.api.types.is_numeric_dtype(col)))\n",
    "#     ].index\n",
    "    \n",
    "#     # Ajouter les noms des colonnes supprimées dans les listes appropriées\n",
    "#     for col in columns_to_drop:\n",
    "#         if null_counts[col] == row_count:\n",
    "#             removed_columns.append(col)  # Colonnes entièrement vides\n",
    "#         elif null_counts[col] > row_count * 0.5 and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "#             non_numeric_columns_to_drop.append(col)  # Colonnes > 50% nulles et non numériques\n",
    "    \n",
    "#     # Supprimer les colonnes identifiées\n",
    "#     df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "#     # Afficher les résultats\n",
    "#     print(\"Colonnes supprimées pour avoir toutes les valeurs nulles:\")\n",
    "#     print(removed_columns)\n",
    "    \n",
    "#     print(\"\\nColonnes supprimées pour avoir plus de 50% de valeurs nulles et être non numériques:\")\n",
    "#     print(non_numeric_columns_to_drop)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# # df_final = pd.read_csv('ton_fichier.csv') # Assure-toi que df_final est bien un DataFrame valide avant d'appeler la fonction\n",
    "# df_final = handle_null_values(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = df_final.round(2)\n",
    "# print(df_final.columns)\n",
    "# df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explore_dict_keys(d, parent_key='', sep='_'):\n",
    "#     \"\"\"\n",
    "#     Explore un dictionnaire récursivement pour obtenir toutes les clés, y compris les sous-clés,\n",
    "#     mais ne retourne pas les valeurs finales.\n",
    "\n",
    "#     :param d: Le dictionnaire à explorer\n",
    "#     :param parent_key: La clé parent qui est utilisée pour concaténer les sous-clés\n",
    "#     :param sep: Le séparateur utilisé pour concaténer les clés (par défaut '_')\n",
    "#     :return: Une liste des clés (et sous-clés)\n",
    "#     \"\"\"\n",
    "#     keys = []\n",
    "#     for k, v in d.items():\n",
    "#         new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "#         if isinstance(v, dict):  # Si la valeur est un dictionnaire, on explore récursivement\n",
    "#             keys.append(new_key)  # Ajouter la clé, mais ne pas inclure la valeur\n",
    "#             keys.extend(explore_dict_keys(v, new_key, sep=sep))  # Continuer l'exploration\n",
    "#         else:\n",
    "#             keys.append(new_key)  # Ajouter la clé finale\n",
    "#     return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_key_path(d, target_key, path=[]):\n",
    "#     \"\"\"\n",
    "#     Recherche récursive d'une clé dans un dictionnaire et retourne son chemin.\n",
    "#     :param d: dictionnaire\n",
    "#     :param target_key: clé recherchée\n",
    "#     :param path: liste pour stocker le chemin jusqu'à la clé\n",
    "#     :return: chemin sous forme de liste\n",
    "#     \"\"\"\n",
    "#     if isinstance(d, dict):  # Si le dictionnaire est encore imbriqué\n",
    "#         for key, value in d.items():\n",
    "#             new_path = path + [key]\n",
    "#             if key == target_key:\n",
    "#                 return new_path\n",
    "#             elif isinstance(value, dict):\n",
    "#                 result = find_key_path(value, target_key, new_path)\n",
    "#                 if result:  # Si la clé est trouvée, retourner le chemin\n",
    "#                     return result\n",
    "#     return None  # Retourne None si la clé n'a pas été trouvée\n",
    "\n",
    "\n",
    "\n",
    "# # Recherche du chemin pour la clé 'marine_data'\n",
    "# path = find_key_path(table_dict, \"Marine Dataframe\")\n",
    "# print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto_convert Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (buoy_id, tables) in enumerate(table_dict.items()):  # Utilisation de .items() pour obtenir (clé, valeur)\n",
    "#     if isinstance(tables, dict):\n",
    "#         if idx == 1:  # Vérifier si l'index est égal à 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Rows of all Dataframes in total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
